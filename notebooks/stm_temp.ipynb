{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "import numpy as np\n",
    "\n",
    "# RとPythonのデータフレームの相互変換を有効化\n",
    "pandas2ri.activate()\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "# サンプルデータの作成\n",
    "data = {\n",
    "    'tokenized_body': [\n",
    "        ['this', 'is', 'a', 'sample', 'document'],\n",
    "        ['another', 'sample', 'document', 'with', 'different', 'words'],\n",
    "        ['text', 'data', 'can', 'be', 'very', 'informative'],\n",
    "        ['this', 'is', 'yet', 'another', 'example', 'of', 'a', 'document'],\n",
    "        ['machine', 'learning', 'models', 'can', 'be', 'complex']\n",
    "    ],\n",
    "    'metadata': [\n",
    "        'Category1',\n",
    "        'Category2',\n",
    "        'Category1',\n",
    "        'Category2',\n",
    "        'Category1'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 語彙リストを作成し、インデックスが1から始まるようにする\n",
    "vocab = sorted(list(set([word for doc in df['tokenized_body'] for word in doc])))  # ソートしてインデックスが連続するようにする\n",
    "vocab_dict = {word: idx + 1 for idx, word in enumerate(vocab)}  # インデックスが1から始まるようにする\n",
    "\n",
    "# 各文書をインデックスと頻度の行列に変換\n",
    "documents = []\n",
    "for doc in df['tokenized_body']:\n",
    "    word_counts = Counter(doc)\n",
    "    indices = [vocab_dict[word] for word in word_counts.keys()]\n",
    "    counts = list(word_counts.values())\n",
    "    documents.append(np.column_stack((indices, counts)))\n",
    "\n",
    "# Rのリスト形式に変換\n",
    "documents_r = ro.ListVector({'doc' + str(i+1): ro.r.matrix(np.array(doc), ncol=2) for i, doc in enumerate(documents)})\n",
    "\n",
    "# RのSTMパッケージをインポート\n",
    "stm = importr('stm')\n",
    "\n",
    "# メタデータの変換（ここでは文字列として扱う）\n",
    "metadata = pandas2ri.py2rpy(df[['metadata']].astype(str))\n",
    "\n",
    "# トピックモデルの作成\n",
    "model = stm.stm(documents=documents_r, vocab=vocab, K=3, prevalence=metadata, data=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
